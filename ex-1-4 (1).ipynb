{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Excercise 1.4\n\nUse the pySINDY algorithm to find the best-fit nonlinear model to describe the data","metadata":{}},{"cell_type":"markdown","source":"We install some usefull libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nfrom sklearn.linear_model import Lasso\nfrom scipy.io import loadmat\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.integrate import solve_ivp\n\n#git clone https://github.com/dynamicslab/pysindy.git\n #   pip install .\n!pip install pysindy\nimport pysindy as ps\n# Ignore matplotlib deprecation warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Seed the random number generators for reproducibility\nnp.random.seed(100)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-19T10:00:21.710003Z","iopub.execute_input":"2022-07-19T10:00:21.710517Z","iopub.status.idle":"2022-07-19T10:00:42.071372Z","shell.execute_reply.started":"2022-07-19T10:00:21.710414Z","shell.execute_reply":"2022-07-19T10:00:42.070097Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We define our data\n\nWe interpolate the data with a spline function, it helps stabilizing the algorithm","metadata":{}},{"cell_type":"code","source":"hare = [20, 20, 52, 83, 64, 68, 83, 12, 36, 150, 110, 60, 7, 10, 70, 100, 92, 70, 10, 11, 137, 137, 18, 22, 52, 83, 18, 10, 9, 65]\nlynx = [32, 50, 12, 10, 13, 36, 15, 12, 6 ,6, 65, 70, 40, 9, 20, 34, 45, 40, 15, 15, 60, 80, 26, 18, 37, 50, 35, 12, 12, 25]\nt0 = 1845;\nt1 = 1903;\ndt = 2;\nt_series = np.arange(t0,t1+dt,dt)-t0\nX = np.stack((hare,lynx),axis=-1)\nprint(np.shape(t_series))\nprint(np.shape(X))\n\nimport scipy\nSp_i = scipy.interpolate.CubicSpline(t_series,X,axis=0)\n\ndt_test = 0.01\nt_test = np.arange(t0,t1,dt_test)-t0\nX_s = Sp_i(t_test)\n\nplt.figure()\nplt.plot(t_test+t0,X_s[:,0],color='b',linestyle='dashed',label='hare SINDy')\nplt.plot(t_test+t0,X_s[:,1],color='r',linestyle='dashed',label='lynx SINDy')\nplt.plot(t_series+t0,X[:,0],color='b',linestyle='solid',label='hare')\nplt.plot(t_series+t0,X[:,1],color='r',linestyle='solid',label='lynx')\nplt.grid()\nplt.legend(fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:00:42.074188Z","iopub.execute_input":"2022-07-19T10:00:42.074915Z","iopub.status.idle":"2022-07-19T10:00:42.416940Z","shell.execute_reply.started":"2022-07-19T10:00:42.074849Z","shell.execute_reply":"2022-07-19T10:00:42.415811Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The first non-linear model is fit","metadata":{}},{"cell_type":"code","source":"# the equations I need to fit are:\n# x'=(b-py)x and y'=(rx-d)y\n# x' = bx-p*xy and y' = r*xy-dy\n\n# MODEL 0\nfeat_names = ['hare','lynx']\nfeat_library = ps.PolynomialLibrary(degree=3)\noptimizer = ps.STLSQ(threshold=0.0001,max_iter=100)\ndifferentiation_method = ps.FiniteDifference(order=3,drop_endpoints=False)\n#differentiation_method = ps.SmoothedFiniteDifference()\n#differentiation_method = ps.SINDyDerivative(kind=\"spline\", s=1e-2)\nmodel0 = ps.SINDy(differentiation_method = differentiation_method,\n            feature_names=feat_names,\n            optimizer=optimizer,\n            feature_library = feat_library)\n\n\nmodel0.fit(X_s,t=t_test)\nmodel0.print()\nprint(\"Feature names:\\n\", model0.get_feature_names())\nintegrator_keywords = {}\n#integrator_keywords['rtol'] = 1e-12\nintegrator_keywords['method'] = 'RK45'#'LSODA' 'Radau'\nintegrator_keywords['max_step'] = 100\nintegrator_keywords['min_step'] = 1\n#integrator_keywords['atol'] = 1e-12","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:00:42.418595Z","iopub.execute_input":"2022-07-19T10:00:42.419064Z","iopub.status.idle":"2022-07-19T10:00:42.503823Z","shell.execute_reply.started":"2022-07-19T10:00:42.419001Z","shell.execute_reply":"2022-07-19T10:00:42.502575Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We compare the original data with the results for the firs model","metadata":{}},{"cell_type":"code","source":"dt_test = 0.01\nt_test = np.arange(t0,t1,dt_test)-t0\nX0 = X[0,:]\nsim = model0.simulate(X0,t_test, integrator_kws=integrator_keywords)\n\nplt.figure()\nplt.plot(t_test+t0,sim[:,0],color='b',linestyle='dashed',label='hare SINDy')\nplt.plot(t_test+t0,sim[:,1],color='r',linestyle='dashed',label='lynx SINDy')\nplt.plot(t_series+t0,X[:,0],color='b',linestyle='solid',label='hare')\nplt.plot(t_series+t0,X[:,1],color='r',linestyle='solid',label='lynx')\nplt.grid()\nplt.legend(fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:00:42.507708Z","iopub.execute_input":"2022-07-19T10:00:42.509740Z","iopub.status.idle":"2022-07-19T10:00:42.944268Z","shell.execute_reply.started":"2022-07-19T10:00:42.509683Z","shell.execute_reply":"2022-07-19T10:00:42.943258Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Bagging\n\nWe perform bagging to see if we can improve the model\n\nAt first we fit 10000 models with a reduced threshold","metadata":{}},{"cell_type":"code","source":"\nensemble_optimizer = ps.STLSQ(threshold=0.0001,max_iter=100)\nlibrary = ps.PolynomialLibrary(degree=3)\nmodel_1 = ps.SINDy(feature_names=feat_names,\n                  optimizer = ensemble_optimizer,\n                  differentiation_method=differentiation_method,\n                  feature_library = library)\nmodel_1.fit(X_s, t=t_test, ensemble=True, quiet=True,replace=True, n_models = 10000,n_subset=24) \nmodel_1.print()\n\nensemble_coefs = (model_1.coef_list)\n\nprint(np.shape(ensemble_coefs))\nprint(model_1.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:00:42.946051Z","iopub.execute_input":"2022-07-19T10:00:42.946792Z","iopub.status.idle":"2022-07-19T10:01:22.892659Z","shell.execute_reply.started":"2022-07-19T10:00:42.946755Z","shell.execute_reply":"2022-07-19T10:01:22.891750Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Make plots of each coefficient distribution!","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\n\nensemble_coefs_1 = np.asarray(ensemble_coefs)\n\nfor j in range(10):\n    for i in range(2):\n        plt.subplot(10, 2, i + 1 + j * 2)\n        if j == 0:\n            plt.title(feat_names[i], fontsize=14)\n        coef_mean = np.mean(ensemble_coefs_1[:,i,j])\n        coef_std = np.std(ensemble_coefs_1[:,i,j])\n        bins = np.linspace(coef_mean-2*coef_std,coef_mean+2*coef_std, 51)#\n        plt.hist(ensemble_coefs_1[:, i, j], color='b', bins=bins, \n                 label='ensemble', align='left')\n\n        plt.grid(True)\n        ax = plt.gca()\n        if i == 0:\n            xticknames = model_1.get_feature_names()\n            plt.ylabel(xticknames[j], fontsize=12)\n        else:\n            ax.set_yticklabels([])\n        plt.ylim(0, 2000)\n        plt.xticks(fontsize=10)\n        plt.yticks(fontsize=10)\n        if i == 2 and j == 9:\n            plt.legend(fontsize=10)\n            \n#plt.savefig('file_name.png')","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:01:22.894014Z","iopub.execute_input":"2022-07-19T10:01:22.895092Z","iopub.status.idle":"2022-07-19T10:01:27.307164Z","shell.execute_reply.started":"2022-07-19T10:01:22.895051Z","shell.execute_reply":"2022-07-19T10:01:27.305798Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Now we try to change slightly the thresholds for the differnet coefficients ","metadata":{}},{"cell_type":"code","source":"library = ps.PolynomialLibrary(degree=3)\nlibrary.fit(X)\nn_features = library.n_output_features_\nthresholds = np.ones((n_features,2))*100\nthresholds[0,:] = .001\nthresholds[1,:] = 0.001\nthresholds [2,:] = 0.001\nthresholds [3,0] = 0.001\n#thresholds[3,:] = 0.0001\n#thresholds[4,:] = 0.0001#0\n#thresholds[5,:] = 0.0001\n#thresholds[6,0] = 0.0001\n#thresholds[7,0] = 0.0001\nthresholds[8,0] = 0.0001\nthresholds[9,0] = 0.0001","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:01:27.309256Z","iopub.execute_input":"2022-07-19T10:01:27.309757Z","iopub.status.idle":"2022-07-19T10:01:27.319103Z","shell.execute_reply.started":"2022-07-19T10:01:27.309703Z","shell.execute_reply":"2022-07-19T10:01:27.317908Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"thresholds = np.ones((n_features,2))*100\nthresholds[0,:] = .01\nthresholds[1,:] = 0.001\nthresholds [2,:] = 0.001\n#thresholds [3,0] = 0.001\nthresholds[3,:] = 0.001\nthresholds[4,:] = 0.0001#0\nthresholds[5,:] = 0.0001\nthresholds[6,:] = 0.0001\nthresholds[7,:] = 0.0001\nthresholds[8,:] = 0.0001\nthresholds[9,:] = 0.0001","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:01:27.320227Z","iopub.execute_input":"2022-07-19T10:01:27.320604Z","iopub.status.idle":"2022-07-19T10:01:27.332908Z","shell.execute_reply.started":"2022-07-19T10:01:27.320569Z","shell.execute_reply":"2022-07-19T10:01:27.331546Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We fit again 10000 models ","metadata":{}},{"cell_type":"code","source":"sr3_optimizer = ps.SR3(thresholder=\"weighted_l0\", thresholds=thresholds,max_iter=100)\nmodel_4 = ps.SINDy(feature_names=feat_names,\n                  optimizer = sr3_optimizer,\n                  differentiation_method=differentiation_method,\n                  feature_library = library)\nn_models = 10000\nmodel_4.fit(X_s, t=t_test, ensemble=True, quiet=True,replace=True, n_models = n_models,n_subset=24) \nmodel_4.print()\n\nw_ensemble_coefs = (model_4.coef_list)\n\nprint(np.shape(w_ensemble_coefs))\nprint(model_4.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:01:27.334134Z","iopub.execute_input":"2022-07-19T10:01:27.335195Z","iopub.status.idle":"2022-07-19T10:02:00.893817Z","shell.execute_reply.started":"2022-07-19T10:01:27.335141Z","shell.execute_reply":"2022-07-19T10:02:00.892314Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"We plot again the distribution of the coefficients","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\n\nw_ensemble_coefs_1 = np.asarray(w_ensemble_coefs)\n\nfor j in range(10):\n    for i in range(2):\n        plt.subplot(10, 2, i + 1 + j * 2)\n        if j == 0:\n            plt.title(feat_names[i], fontsize=14)\n        coef_mean = np.mean(w_ensemble_coefs_1[:,i,j])\n        coef_std = np.std(w_ensemble_coefs_1[:,i,j])\n        bins = np.linspace(coef_mean-2*coef_std,coef_mean+2*coef_std, 51)#\n        plt.hist(w_ensemble_coefs_1[:, i, j], color='b', bins=bins, \n                 label='ensemble', align='left')\n\n        plt.grid(True)\n        ax = plt.gca()\n        if i == 0:\n            xticknames = model_4.get_feature_names()\n            plt.ylabel(xticknames[j], fontsize=12)\n        else:\n            ax.set_yticklabels([])\n\n        plt.ylim(0, 500)\n\n        plt.xticks(fontsize=10)\n        plt.yticks(fontsize=10)\n        if i == 2 and j == 9:\n            plt.legend(fontsize=10)\n            \n#plt.savefig('thres_w.png')","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:02:00.897344Z","iopub.execute_input":"2022-07-19T10:02:00.897701Z","iopub.status.idle":"2022-07-19T10:02:05.148156Z","shell.execute_reply.started":"2022-07-19T10:02:00.897666Z","shell.execute_reply":"2022-07-19T10:02:05.146936Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"We simulate and plot randomly one of the models","metadata":{}},{"cell_type":"code","source":"w_ensemble_coefs_1.shape[0]\ni0 = np.random.randint(0,n_models)\nprint(i0)\n#i0=261\nsr3_optimizer.coef_ = w_ensemble_coefs_1[i0,:,:]\nprint( w_ensemble_coefs_1[i0,:,:])\nintegrator_keywords = {}\n#integrator_keywords['rtol'] = 1e-12\nintegrator_keywords['method'] = 'RK45'#'LSODA' 'RK45'\nintegrator_keywords['max_step'] = 100\nintegrator_keywords['min_step'] = 1\nx_test_i = model_4.simulate(X0,t_test,integrator='odeint')#,integrator_kws=integrator_keywords)integrator='odeint'\nprint(np.shape(x_test_i))\nif np.shape(x_test_i)[0] == 5800:\n    plt.figure()\n    plt.plot(t_test+t0,x_test_i[:,0],color='b',linestyle='dashed',label='hare SINDy')\n    plt.plot(t_test+t0,x_test_i[:,1],color='r',linestyle='dashed',label='lynx SINDy')\n    plt.plot(t_series+t0,X[:,0],color='b',linestyle='solid',label='hare')\n    plt.plot(t_series+t0,X[:,1],color='r',linestyle='solid',label='lynx')\n    plt.grid()\n    plt.legend(fontsize=12)\n    plt.show()\n\nprint([(np.var(x_test_i[-1000:-1,0]) , np.var(x_test_i[-1000:-1,1]) )])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:02:05.149748Z","iopub.execute_input":"2022-07-19T10:02:05.150257Z","iopub.status.idle":"2022-07-19T10:02:05.514513Z","shell.execute_reply.started":"2022-07-19T10:02:05.150205Z","shell.execute_reply":"2022-07-19T10:02:05.513341Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We simulate all of the models in order to exclude the unstable ones and the ones that saturate in time","metadata":{}},{"cell_type":"code","source":"x_test_4 = np.zeros([n_models,5800,2])\nX0 = X[1]\nns = 0\nnt = 0\ncoef_stable = []\ncoef_unstable = []\nx_test_i = np.zeros((2,5800))\nx_test_stable =  np.zeros([n_models,5800,2])\ncoef_unstable = np.zeros([n_models,2,10])\ncoef_stable = np.zeros([n_models,2,10])\n\nfor i in range(w_ensemble_coefs_1.shape[0]):\n    sr3_optimizer.coef_ = w_ensemble_coefs_1[i,:,:]\n    x_test_i = model_4.simulate(X0,t_test,integrator = 'odeint')#,integrator_kws=integrator_keywords)\n\n    if np.shape(x_test_i)[0] == 5800:\n        x_test_4[i,:,:] = x_test_i\n        if np.any(np.abs(x_test_i) > 400) or (np.var(x_test_i[-1000:-1,0])< 1 or np.var(x_test_i[-1000:-1,1]) < 1):\n\n            coef_unstable[ns,:,:] = w_ensemble_coefs_1[i,:,:]\n            ns =ns+1\n        else:\n            coef_stable[nt,:,:] = (w_ensemble_coefs_1[i,:,:])\n            x_test_stable[nt,:,:] = (x_test_i)\n            nt =nt+1\n    else:\n        coef_unstable[ns,:,:] = w_ensemble_coefs_1[i,:,:]\n        ns =ns+1 \n    \nprint(np.shape(coef_stable))\nprint([ns,'unstable models out of ',n_models])","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-19T10:02:05.516216Z","iopub.execute_input":"2022-07-19T10:02:05.516583Z","iopub.status.idle":"2022-07-19T10:58:04.090443Z","shell.execute_reply.started":"2022-07-19T10:02:05.516551Z","shell.execute_reply":"2022-07-19T10:58:04.089470Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"We simulate the stable models","metadata":{}},{"cell_type":"code","source":"coef_stable_1 = coef_stable[0:(n_models-ns),:,:]\nx_test_stable = np.zeros([nt,5800,2])\nX0 = X[1]\n\nfor i in range(nt):\n    sr3_optimizer.coef_ = coef_stable_1[i,:,:]\n\n    x_test_stable[i,:,:] = model_4.simulate(X0,t_test,integrator = 'odeint')\n    \nmean_x_stable = np.mean(x_test_stable,axis=0)\nplt.figure()\nplt.plot(t_test+t0,mean_x_stable[:,0],color='b',linestyle='dashed',label='hare SINDy')\nplt.plot(t_test+t0,mean_x_stable[:,1],color='r',linestyle='dashed',label='lynx SINDy')\nplt.plot(t_series+t0,X[:,0],color='b',linestyle='solid',label='hare')\nplt.plot(t_series+t0,X[:,1],color='r',linestyle='solid',label='lynx')\nplt.grid()\nplt.legend(fontsize=12)\nplt.show()    \n#print(np.shape(coef_stable))\n#print([ns,'unstable models out of ',n_models])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T10:58:04.091913Z","iopub.execute_input":"2022-07-19T10:58:04.092269Z","iopub.status.idle":"2022-07-19T11:00:59.733625Z","shell.execute_reply.started":"2022-07-19T10:58:04.092237Z","shell.execute_reply":"2022-07-19T11:00:59.732444Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"We plot the distributions of the coefficients of the models we selected ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\n\nfor j in range(10):\n    for i in range(2):\n        plt.subplot(10, 2, i + 1 + j * 2)\n        if j == 0:\n            plt.title(feat_names[i], fontsize=14)\n        coef_mean = np.mean(coef_stable_1[:,i,j])\n        coef_std = np.std(coef_stable_1[:,i,j])\n        bins = np.linspace(coef_mean-2*coef_std,coef_mean+2*coef_std, 51)#\n        plt.hist(coef_stable_1[:, i, j], color='b', bins=bins, \n                 label='ensemble', align='left')\n\n        plt.grid(True)\n        ax = plt.gca()\n        if i == 0:\n            xticknames = model_4.get_feature_names()\n            plt.ylabel(xticknames[j], fontsize=12)\n        else:\n            ax.set_yticklabels([])\n\n        plt.ylim(0, 50)\n        plt.xticks(fontsize=10)\n        plt.yticks(fontsize=10)\n        if i == 2 and j == 9:\n            plt.legend(fontsize=10)\n            \n#plt.savefig('thres_w.png')","metadata":{"execution":{"iopub.status.busy":"2022-07-19T11:00:59.735510Z","iopub.execute_input":"2022-07-19T11:00:59.736223Z","iopub.status.idle":"2022-07-19T11:01:03.834486Z","shell.execute_reply.started":"2022-07-19T11:00:59.736171Z","shell.execute_reply":"2022-07-19T11:01:03.833224Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"np.shape(coef_stable_1)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T11:01:03.835992Z","iopub.execute_input":"2022-07-19T11:01:03.836418Z","iopub.status.idle":"2022-07-19T11:01:03.844998Z","shell.execute_reply.started":"2022-07-19T11:01:03.836383Z","shell.execute_reply":"2022-07-19T11:01:03.843720Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"We calculate the mean values of the coefficients and use them to make the prediction","metadata":{}},{"cell_type":"code","source":"coef_stable_1 = coef_stable[0:(n_models-ns),:,:]\ncosef_mean = np.mean(coef_stable_1,axis=0)\nsr3_optimizer.coef_ = cosef_mean\nx_test_mean = model_4.simulate(X0,t_test,integrator = 'odeint')\n\ndt_test = 0.01\nt_test = np.arange(t0,t1,dt_test)-t0\nX0 = X[0,:]\nsim = model0.simulate(X0,t_test, integrator_kws=integrator_keywords)\n\nplt.figure()\nplt.plot(t_test+t0,x_test_mean[:,0],color='b',linestyle='dashed',label='hare SINDy')\nplt.plot(t_test+t0,x_test_mean[:,1],color='r',linestyle='dashed',label='lynx SINDy')\nplt.plot(t_series+t0,X[:,0],color='b',linestyle='solid',label='hare')\nplt.plot(t_series+t0,X[:,1],color='r',linestyle='solid',label='lynx')\nplt.grid()\nplt.legend(fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T11:01:03.846855Z","iopub.execute_input":"2022-07-19T11:01:03.847338Z","iopub.status.idle":"2022-07-19T11:01:04.454999Z","shell.execute_reply.started":"2022-07-19T11:01:03.847292Z","shell.execute_reply":"2022-07-19T11:01:04.453815Z"},"trusted":true},"execution_count":16,"outputs":[]}]}